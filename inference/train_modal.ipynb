{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modal Decomposition Model\n",
    "\n",
    "This model is an adaptation of the math behind the economic complexity index, proposed by Hidalgo and Hausmann in this paper (https://www.pnas.org/content/106/26/10570.short ), explained in detail in section in this supplementary material (https://www.pnas.org/content/suppl/2009/06/22/0900943106.DCSupplemental/Appendix_PDF.pdf ).\n",
    "\n",
    "\n",
    "INSERT EXPLANATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import models\n",
    "from permutation_metrics import rank_similarities, rank_similarities_real\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "A_true = np.load('../datasets/students_uncorrel.npy')\n",
    "D_true = np.load('../datasets/questions_uncorrel.npy')\n",
    "\n",
    "num_students = A_true.shape[0]\n",
    "num_questions = D_true.shape[0]\n",
    "guess_prob = 1/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Sigmoid function.\n",
    "\n",
    "    :param x: Argument to the function\n",
    "    :return: The sigmoid of x\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_irf(a, c, d):\n",
    "    \"\"\"\n",
    "\n",
    "    :param a: ability\n",
    "    :param c: guess probability\n",
    "    :param d: difficulty\n",
    "    \n",
    "    :return: the probability that the student will get the question right\n",
    "    \"\"\"\n",
    "    return c + (1 - c) * sigmoid(a - d)\n",
    "\n",
    "\n",
    "def floored_exp_irf(a, d, l, c):\n",
    "    \"\"\"\n",
    "    Floored exponential function with parameters lambda, a and d.\n",
    "\n",
    "    :param l: lambda, slope for exponential curve\n",
    "    :param a: ability: [0, 1]\n",
    "    :param d: difficulty: [0, 1]\n",
    "    :param c: guess probability\n",
    "\n",
    "    :return: the probability that the student will get the question right\n",
    "    \"\"\"\n",
    "    return np.maximum(c, 1 - np.exp(-l*(a-d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE Simulated Data (Uncorrelated)\n",
    "\n",
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE(A, A_true) =  0.2958020117826889\n",
      "RMSE(D, D_true) =  0.3690547366615422\n",
      "\n",
      "    Summary of Ranking Evaluation: \n",
      "    Correlations with true rankings derived from A_true.\n",
      "        Baseline: \n",
      "            Kendall:0.847 (p-value 0.0)\n",
      "            Spearman: 0.966 (p-value 0.0) \n",
      "            \n",
      "        Prediction:\n",
      "            Kendall: 0.494 (p-value 0.0)\n",
      "            Spearman: 0.693 (p-value 0.0)  \n",
      "            \n",
      "    Average difference: -0.313 (absolute diff., vs. the baseline) \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "R = np.load('../datasets/floored_exp_uncorrel.npy')\n",
    "\n",
    "s, q = models.modal_decomp(R)\n",
    "print('RMSE(A, A_true) = ', utils.rmse(s, A_true))\n",
    "print('RMSE(D, D_true) = ', utils.rmse(q, D_true))\n",
    "\n",
    "print(rank_similarities(A_true, R, np.expand_dims(s, axis=1))['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle acc = 0.4884567901234568\n",
      "Sigmoid test acc = 0.6222222222222222\n",
      "FE test acc = 0.45555555555555555\n"
     ]
    }
   ],
   "source": [
    "train = R[:int(num_students*0.8)]\n",
    "test = R[int(num_students*0.8):]\n",
    "\n",
    "_, q = models.modal_decomp(train)\n",
    "s, _ = models.modal_decomp(test[:, :-1])\n",
    "\n",
    "probs_sigmoid = sigmoid_irf(s, q[-1], guess_prob)\n",
    "probs_fe = floored_exp_irf(s, q[-1], 10, guess_prob)\n",
    "\n",
    "preds_sigmoid = (probs_sigmoid >= 0.5).astype(int)\n",
    "preds_fe = (probs_fe >= 0.5).astype(int)\n",
    "\n",
    "preds_oracle = (floored_exp_irf(A_true[int(num_students*0.8):], D_true[-1], 10, guess_prob) >= 0.5).astype(int)\n",
    "\n",
    "print('Oracle acc = {}'.format(np.mean((preds_oracle == test[:, -1]).astype(int))))\n",
    "print('Sigmoid test acc = {}'.format(np.mean((preds_sigmoid == test[:, -1]).astype(int))))\n",
    "print('FE test acc = {}'.format(np.mean((preds_fe == test[:, -1]).astype(int))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid Simulated Data (Uncorrelated)\n",
    "\n",
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE(A, A_true) =  0.2878212241644609\n",
      "RMSE(D, D_true) =  0.30075461144800103\n",
      "\n",
      "    Summary of Ranking Evaluation: \n",
      "    Correlations with true rankings derived from A_true.\n",
      "        Baseline: \n",
      "            Kendall:0.434 (p-value 0.0)\n",
      "            Spearman: 0.608 (p-value 0.0) \n",
      "            \n",
      "        Prediction:\n",
      "            Kendall: -0.016 (p-value 0.439)\n",
      "            Spearman: -0.026 (p-value 0.416)  \n",
      "            \n",
      "    Average difference: -0.542 (absolute diff., vs. the baseline) \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "R = np.load('../datasets/sigmoid_irf_uncorrel.npy')\n",
    "\n",
    "s, q = models.modal_decomp(R)\n",
    "print('RMSE(A, A_true) = ', utils.rmse(s, A_true))\n",
    "print('RMSE(D, D_true) = ', utils.rmse(q, D_true))\n",
    "\n",
    "print(rank_similarities(A_true, R, np.expand_dims(s, axis=1))['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid test acc = 0.6222222222222222\n",
      "FE test acc = 0.45555555555555555\n",
      "Oracle acc = 0.6222222222222222\n"
     ]
    }
   ],
   "source": [
    "train = R[:int(num_students*0.8)]\n",
    "test = R[int(num_students*0.8):]\n",
    "\n",
    "_, q = models.modal_decomp(train)\n",
    "s, _ = models.modal_decomp(test[:, :-1])\n",
    "\n",
    "probs_sigmoid = sigmoid_irf(s, q[-1], guess_prob)\n",
    "probs_fe = floored_exp_irf(s, q[-1], 10, guess_prob)\n",
    "\n",
    "preds_sigmoid = (probs_sigmoid >= 0.5).astype(int)\n",
    "preds_fe = (probs_fe >= 0.5).astype(int)\n",
    "\n",
    "preds_oracle = (sigmoid_irf(A_true[int(num_students*0.8):], D_true[-1], guess_prob) >= 0.5).astype(int)\n",
    "\n",
    "print('Sigmoid test acc = {}'.format(np.mean((preds_sigmoid == test[:, -1]).astype(int))))\n",
    "print('FE test acc = {}'.format(np.mean((preds_fe == test[:, -1]).astype(int))))\n",
    "\n",
    "print('Oracle acc = {}'.format(np.mean((preds_oracle == test[:, -1]).astype(int))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Data\n",
    "\n",
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Summary of Ranking Evaluation:\n",
      "    Correlations between R and A_pred.\n",
      "    \n",
      "        Baseline: \n",
      "            Kendall:0.138 (p-value 0.0)\n",
      "            Spearman: 0.195 (p-value 0.0) \n",
      "            \n",
      "        Average Correlation: 0.166\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "R = np.genfromtxt('../datasets/real_data.csv', delimiter=',')\n",
    "num_students, num_questions = R.shape\n",
    "\n",
    "s, q = models.modal_decomp(R)\n",
    "\n",
    "print(rank_similarities_real(R, np.expand_dims(1-s, axis=1))['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid test acc = 0.76875\n",
      "FE test acc = 0.4875\n"
     ]
    }
   ],
   "source": [
    "train = R[:int(num_students*0.8)]\n",
    "test = R[int(num_students*0.8):]\n",
    "\n",
    "_, q = models.modal_decomp(train)\n",
    "s, _ = models.modal_decomp(test[:, :-1])\n",
    "\n",
    "probs_sigmoid = sigmoid_irf(s, q[-1], guess_prob)\n",
    "probs_fe = floored_exp_irf(s, q[-1], 10, guess_prob)\n",
    "\n",
    "preds_sigmoid = (probs_sigmoid >= 0.5).astype(int)\n",
    "preds_fe = (probs_fe >= 0.5).astype(int)\n",
    "\n",
    "print('Sigmoid test acc = {}'.format(np.mean((preds_sigmoid == test[:, -1]).astype(int))))\n",
    "print('FE test acc = {}'.format(np.mean((preds_fe == test[:, -1]).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
