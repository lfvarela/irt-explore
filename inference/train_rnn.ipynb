{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "from permutation_metrics import rank_similarities\n",
    "import utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "Y = torch.tensor(np.load('../datasets/sigmoid_irf_uncorrel.npy'), dtype=dtype)\n",
    "Yt = Y.transpose(0,1)\n",
    "real_data = torch.tensor(np.genfromtxt('../datasets/real_data.csv', delimiter = ','), dtype = dtype)\n",
    "A_true = np.load('../datasets/students_uncorrel.npy')\n",
    "D_true = np.load('../datasets/questions_uncorrel.npy')\n",
    "\n",
    "# We assume we know the relevant concept of each question beforehand\n",
    "concepts = np.nonzero(D_true)\n",
    "num_students, num_concepts = A_true.shape\n",
    "num_questions = D_true.shape[0]\n",
    "guess_prob = 1/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(R_pred, R_true):\n",
    "    R_pred = R_pred.data.numpy()\n",
    "    R_true = R_true.data.numpy()\n",
    "    R_pred_cpy = np.copy(R_pred)\n",
    "    R_pred_cpy[R_pred_cpy > 0.5] = 1\n",
    "    R_pred_cpy[R_pred_cpy <= 0.5] = 0\n",
    "    print(\"Accuracy: {}\".format(np.sum(R_pred_cpy == R_true) / (R_true.shape[0]*R_true.shape[1])))\n",
    "    return np.sum(R_pred_cpy == R_true) / (R_true.shape[0]*R_true.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_last(R_pred, R_true):\n",
    "    R_pred = R_pred.data.numpy()\n",
    "    R_true = R_true.data.numpy()\n",
    "    R_pred_cpy = np.copy(R_pred)\n",
    "    R_pred_cpy[R_pred_cpy > 0.5] = 1\n",
    "    R_pred_cpy[R_pred_cpy <= 0.5] = 0\n",
    "    print(\"Accuracy: {}\".format(np.sum(R_pred_cpy == R_true) / (R_true.shape[0])))\n",
    "    return np.sum(R_pred_cpy == R_true) / (R_true.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_min_max(A,B):\n",
    "    a_norm = (A - A.min())/(A.max()-A.min())\n",
    "    b_norm = (B - B.min())/(B.max()-B.min())\n",
    "    return np.sqrt(np.mean(np.square(a_norm-b_norm))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing to train simulated data set\n",
    "#observations = (real_data.transpose(0,1))\n",
    "observations = Yt\n",
    "idx_train = int(0.7*observations.size()[1])\n",
    "idx_val = int(0.8*observations.size()[1])\n",
    "train = observations[:,:idx_train]\n",
    "val = observations[:,idx_train:idx_val]\n",
    "test = observations[:,idx_val:]\n",
    "idx_test = observations.size()[1] - idx_val\n",
    "idx_val = idx_val-idx_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN to predict students performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "hidden_size = 128\n",
    "layers = 4\n",
    "batch_size = 100 #needs to have idx_train, idx_val, and idx_train as a multiple\n",
    "rate = 0.002\n",
    "dropout = 0.5\n",
    "\n",
    "model = models.RNN_Model(hidden_size, batch_size, layers, dropout)\n",
    "criterion = nn.functional.binary_cross_entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.6935)\n",
      "Accuracy: 0.5069196428571429\n",
      "20 tensor(0.5866)\n",
      "Accuracy: 0.70625\n",
      "40 tensor(0.4788)\n",
      "Accuracy: 0.74375\n",
      "60 tensor(0.5297)\n",
      "Accuracy: 0.7265625\n",
      "80 tensor(0.4069)\n",
      "Accuracy: 0.7816964285714286\n",
      "100 tensor(0.3784)\n",
      "Accuracy: 0.7875\n",
      "120 tensor(0.3377)\n",
      "Accuracy: 0.8296875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-190e059c6692>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#if batch % 2 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training\n",
    "losses = np.zeros(n_epochs) # For plotting\n",
    "num_batches = int(idx_train/batch_size)\n",
    "preds = torch.zeros(train.size()[0]-1,train.size()[1])\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for batch in range(num_batches):\n",
    "        inputs = Variable(train[:-1,batch*batch_size:(batch+1)*batch_size])\n",
    "        targets = Variable(train[1:,batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "        outputs, hidden = model(inputs, None)\n",
    "        preds[:,batch*batch_size:(batch+1)*batch_size] = outputs\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #if batch % 2 == 0:\n",
    "            #print(\"Batch Done\")\n",
    "    if epoch % 20 == 0:\n",
    "        losses[epoch] += loss.data[0]\n",
    "        print(epoch, loss.data[0])\n",
    "        accuracy(preds, train[1:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6125"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation\n",
    "num_batches = int(idx_val/batch_size)\n",
    "preds = torch.zeros(val.size()[0]-1,val.size()[1])\n",
    "\n",
    "for batch in range(num_batches):\n",
    "    inputs = Variable(val[:-1,batch*batch_size:(batch+1)*batch_size])\n",
    "    targets = Variable(val[1:,batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "    outputs, hidden = model(inputs, None)\n",
    "    preds[:,batch*batch_size:(batch+1)*batch_size] = outputs\n",
    "    \n",
    "accuracy(preds, val[1:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "num_batches = int(idx_test/batch_size)\n",
    "preds = torch.zeros(test.size()[0]-1,test.size()[1])\n",
    "\n",
    "for batch in range(num_batches):\n",
    "    inputs = Variable(test[:-1,batch*batch_size:(batch+1)*batch_size])\n",
    "    targets = Variable(test[1:,batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "    outputs, hidden = model(inputs, None)\n",
    "    preds[:,batch*batch_size:(batch+1)*batch_size] = outputs\n",
    "\n",
    "accuracy(preds, test[1:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skill RNN to predict students performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "batch_size = 100\n",
    "average = True\n",
    "sigmoid = True\n",
    "#concepts = ([0,1,2,3,4,5,6,7,8],[0,0,0,0,0,0,0,0,0]) #use for real data\n",
    "#num_questions = observations.size()[0] #use for real data\n",
    "hidden_size = 128\n",
    "dropout = 0.3\n",
    "num_layers = 4\n",
    "rate = 0.002\n",
    "\n",
    "model = models.RNN_Skills_Model(average, concepts, num_concepts, num_questions, hidden_size, batch_size, num_layers, dropout, sigmoid)\n",
    "criterion = nn.functional.binary_cross_entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.6659)\n",
      "Accuracy: 0.6216161616161616\n",
      "RMSE A: 0.36275818294578815\n",
      "RMSE D: 0.3133944586925653\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6103030303030303\n",
      "RMSE A: 0.43053038866326837\n",
      "RMSE D: 0.3133944586925653\n",
      "20 tensor(0.6581)\n",
      "Accuracy: 0.6216161616161616\n",
      "RMSE A: 0.47423078724709977\n",
      "RMSE D: 0.3246873408706138\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6103030303030303\n",
      "RMSE A: 0.48879502161687066\n",
      "RMSE D: 0.3246873408706138\n",
      "40 tensor(0.6567)\n",
      "Accuracy: 0.6216161616161616\n",
      "RMSE A: 0.4456044207391143\n",
      "RMSE D: 0.3417772910457605\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6103030303030303\n",
      "RMSE A: 0.4624564143724898\n",
      "RMSE D: 0.3417772910457605\n",
      "60 tensor(0.6530)\n",
      "Accuracy: 0.6216161616161616\n",
      "RMSE A: 0.3501082197854326\n",
      "RMSE D: 0.34853465143705226\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6103030303030303\n",
      "RMSE A: 0.41121953913350423\n",
      "RMSE D: 0.34853465143705226\n",
      "80 tensor(0.6447)\n",
      "Accuracy: 0.6217027417027418\n",
      "RMSE A: 0.2695449888691595\n",
      "RMSE D: 0.3508403598848586\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6102020202020202\n",
      "RMSE A: 0.3679888401429524\n",
      "RMSE D: 0.3508403598848586\n",
      "100 tensor(0.6316)\n",
      "Accuracy: 0.6230735930735931\n",
      "RMSE A: 0.236800651337046\n",
      "RMSE D: 0.3513369712901148\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6104040404040404\n",
      "RMSE A: 0.3324473037512107\n",
      "RMSE D: 0.3513369712901148\n",
      "120 tensor(0.6220)\n",
      "Accuracy: 0.6269119769119769\n",
      "RMSE A: 0.22454843713722283\n",
      "RMSE D: 0.3494793095820786\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6083838383838384\n",
      "RMSE A: 0.3207800215943128\n",
      "RMSE D: 0.3494793095820786\n",
      "140 tensor(0.6131)\n",
      "Accuracy: 0.6314718614718615\n",
      "RMSE A: 0.2086153735197528\n",
      "RMSE D: 0.34793962598120787\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6087878787878788\n",
      "RMSE A: 0.3316947208643561\n",
      "RMSE D: 0.34793962598120787\n",
      "160 tensor(0.6077)\n",
      "Accuracy: 0.634025974025974\n",
      "RMSE A: 0.20793809698954768\n",
      "RMSE D: 0.3474386139967301\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6063636363636363\n",
      "RMSE A: 0.32678390456614953\n",
      "RMSE D: 0.3474386139967301\n",
      "180 tensor(0.6036)\n",
      "Accuracy: 0.6358441558441559\n",
      "RMSE A: 0.20374264848030815\n",
      "RMSE D: 0.347784833007435\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6070707070707071\n",
      "RMSE A: 0.3208432319199875\n",
      "RMSE D: 0.347784833007435\n",
      "200 tensor(0.6011)\n",
      "Accuracy: 0.636984126984127\n",
      "RMSE A: 0.20279035690304548\n",
      "RMSE D: 0.34753687672793926\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6069696969696969\n",
      "RMSE A: 0.32786551588548546\n",
      "RMSE D: 0.34753687672793926\n",
      "220 tensor(0.5984)\n",
      "Accuracy: 0.6377056277056277\n",
      "RMSE A: 0.20003970184637018\n",
      "RMSE D: 0.3479347629954831\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6057575757575757\n",
      "RMSE A: 0.3217580648775548\n",
      "RMSE D: 0.3479347629954831\n",
      "240 tensor(0.5956)\n",
      "Accuracy: 0.6384559884559885\n",
      "RMSE A: 0.19967004592606835\n",
      "RMSE D: 0.348132030286965\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6086868686868687\n",
      "RMSE A: 0.33312876564341465\n",
      "RMSE D: 0.348132030286965\n",
      "260 tensor(0.5938)\n",
      "Accuracy: 0.6391919191919192\n",
      "RMSE A: 0.2013177046214289\n",
      "RMSE D: 0.34817383884719844\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6082828282828283\n",
      "RMSE A: 0.3258878089496169\n",
      "RMSE D: 0.34817383884719844\n",
      "280 tensor(0.5910)\n",
      "Accuracy: 0.638961038961039\n",
      "RMSE A: 0.19936724555129176\n",
      "RMSE D: 0.348781253968315\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.607979797979798\n",
      "RMSE A: 0.32397667798792373\n",
      "RMSE D: 0.348781253968315\n",
      "300 tensor(0.5896)\n",
      "Accuracy: 0.6397546897546897\n",
      "RMSE A: 0.19610050113800423\n",
      "RMSE D: 0.34908936227005744\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6083838383838384\n",
      "RMSE A: 0.33706937975960966\n",
      "RMSE D: 0.34908936227005744\n",
      "320 tensor(0.5884)\n",
      "Accuracy: 0.6398845598845598\n",
      "RMSE A: 0.20003885292474996\n",
      "RMSE D: 0.3487929575421388\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6061616161616161\n",
      "RMSE A: 0.3281258133626206\n",
      "RMSE D: 0.3487929575421388\n",
      "340 tensor(0.5867)\n",
      "Accuracy: 0.6395526695526695\n",
      "RMSE A: 0.19737745651565808\n",
      "RMSE D: 0.34858093689353614\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6077777777777778\n",
      "RMSE A: 0.3259079277460169\n",
      "RMSE D: 0.34858093689353614\n",
      "360 tensor(0.5860)\n",
      "Accuracy: 0.6404473304473305\n",
      "RMSE A: 0.2006689977546368\n",
      "RMSE D: 0.348392557715696\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6065656565656565\n",
      "RMSE A: 0.3132640383009427\n",
      "RMSE D: 0.348392557715696\n",
      "380 tensor(0.5845)\n",
      "Accuracy: 0.6404329004329005\n",
      "RMSE A: 0.19826033702369672\n",
      "RMSE D: 0.348487991179584\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6083838383838384\n",
      "RMSE A: 0.3289272711674459\n",
      "RMSE D: 0.348487991179584\n",
      "400 tensor(0.5836)\n",
      "Accuracy: 0.6412409812409813\n",
      "RMSE A: 0.2022883561288142\n",
      "RMSE D: 0.34818127385982506\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6054545454545455\n",
      "RMSE A: 0.34095183083341135\n",
      "RMSE D: 0.34818127385982506\n",
      "420 tensor(0.5828)\n",
      "Accuracy: 0.6412698412698413\n",
      "RMSE A: 0.19765439571599344\n",
      "RMSE D: 0.34850889901499293\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6067676767676767\n",
      "RMSE A: 0.31952177395292886\n",
      "RMSE D: 0.34850889901499293\n",
      "440 tensor(0.5834)\n",
      "Accuracy: 0.6420346320346321\n",
      "RMSE A: 0.2002670383981008\n",
      "RMSE D: 0.3487154373985777\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6050505050505051\n",
      "RMSE A: 0.330924243237986\n",
      "RMSE D: 0.3487154373985777\n",
      "460 tensor(0.6595)\n",
      "Accuracy: 0.619004329004329\n",
      "RMSE A: 0.29489842370208474\n",
      "RMSE D: 0.34921063161573984\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6101010101010101\n",
      "RMSE A: 0.30301808798663565\n",
      "RMSE D: 0.34921063161573984\n",
      "480 tensor(0.6570)\n",
      "Accuracy: 0.6213564213564213\n",
      "RMSE A: 0.23460883547124117\n",
      "RMSE D: 0.34894155073960964\n",
      "Validation\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.6104040404040404\n",
      "RMSE A: 0.26705002877754225\n",
      "RMSE D: 0.34894155073960964\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "losses = np.zeros(n_epochs) # For plotting\n",
    "num_batches = int(idx_train/batch_size)\n",
    "preds = torch.zeros(train.size()[0]-1,train.size()[1])\n",
    "A_pred = torch.zeros(train.size()[1],num_concepts)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    num_batches = int(idx_train/batch_size)\n",
    "    preds = torch.zeros(train.size()[0]-1,train.size()[1])\n",
    "    A_pred = torch.zeros(train.size()[1],num_concepts)\n",
    "    for batch in range(num_batches):\n",
    "        inputs = Variable(train[:-1,batch*batch_size:(batch+1)*batch_size])\n",
    "        targets = Variable(train[1:,batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "        outputs, hidden, skills, D = model(inputs, None)\n",
    "        preds[:,batch*batch_size:(batch+1)*batch_size] = outputs\n",
    "        A_pred[batch*batch_size:(batch+1)*batch_size,:] = skills \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    losses[epoch] += loss.data[0]\n",
    "    \n",
    "    \n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(epoch, loss.data[0])\n",
    "        accuracy(preds,train[1:,:])\n",
    "        print('RMSE A: {}'.format(rmse_min_max(A_pred.data.numpy(), A_true[:idx_train])))\n",
    "        print('RMSE D: {}'.format(rmse_min_max(D.data.numpy(), D_true)))\n",
    "        \n",
    "        print(\"Validation\")\n",
    "        num_batches = int(idx_val/batch_size)\n",
    "        preds = torch.zeros(val.size()[0]-1,val.size()[1])\n",
    "        A_pred_val = torch.zeros(val.size()[1],num_concepts)\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            inputs = Variable(val[:-1,batch*batch_size:(batch+1)*batch_size])\n",
    "            targets = Variable(val[1:,batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "            outputs, hidden, skills, D = model(inputs, None)\n",
    "            preds[:,batch*batch_size:(batch+1)*batch_size] = outputs\n",
    "            A_pred_val[batch*batch_size:(batch+1)*batch_size,:] = skills \n",
    "\n",
    "        accuracy_last(preds[-1,:], val[-1,:])\n",
    "        accuracy(preds, val[1:,:])\n",
    "        print('RMSE A: {}'.format(rmse_min_max(A_pred_val.data.numpy(), A_true[idx_train:(idx_train+idx_val)])))\n",
    "        print('RMSE D: {}'.format(rmse_min_max(D.data.numpy(), D_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 700])\n",
      "\n",
      "        Summary of Ranking Evaluation: \n",
      "        The correlations are with the true rankings derived from A_true.\n",
      "        For the baseline, we get a Kendall Rank correlation of -0.06, with p-value of 0.017, and a Spearman correlation of -0.091, with p-value of 0.016. \n",
      "        For the prediction, we get a Kendall Rank correlation of 0.042, with p-value of 0.096, and a Spearman correlation of 0.062, with p-value of 0.101.  \n",
      "        Which gives us an average difference of 0.1275 versus the baseline. \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "results = rank_similarities(A_true[:idx_train],train.transpose(0,1).data.numpy(), A_pred.data.numpy())\n",
    "print(results['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE A: 0.2703796576799514\n",
      "RMSE D: 0.3517747783233809\n",
      "Accuracy: 0.6096969696969697\n",
      "Accuracy: 0.58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation\n",
    "num_batches = int(idx_val/batch_size)\n",
    "preds = torch.zeros(val.size()[0]-1,val.size()[1])\n",
    "A_pred = torch.zeros(val.size()[1],num_concepts)\n",
    "\n",
    "for batch in range(num_batches):\n",
    "    inputs = Variable(val[:-1,batch*batch_size:(batch+1)*batch_size])\n",
    "    targets = Variable(val[1:,batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "    outputs, hidden, skills, D = model(inputs, None)\n",
    "    preds[:,batch*batch_size:(batch+1)*batch_size] = outputs\n",
    "    A_pred[batch*batch_size:(batch+1)*batch_size,:] = skills \n",
    "    \n",
    "print('RMSE A: {}'.format(rmse_min_max(A_pred.data.numpy(), A_true[idx_train:(idx_train+idx_val)])))\n",
    "print('RMSE D: {}'.format(rmse_min_max(D.data.numpy(), D_true)))\n",
    "accuracy(preds, val[1:,:])\n",
    "accuracy_last(preds[-1,:], val[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE A: 0.25209384311499305\n",
      "RMSE D: 0.3517747783233809\n",
      "Accuracy: 0.6196969696969697\n",
      "Accuracy: 0.65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "num_batches = int(idx_test/batch_size)\n",
    "preds = torch.zeros(test.size()[0]-1,test.size()[1])\n",
    "A_pred = torch.zeros(test.size()[1],num_concepts)\n",
    "\n",
    "for batch in range(num_batches):\n",
    "    inputs = Variable(test[:-1,batch*batch_size:(batch+1)*batch_size])\n",
    "    targets = Variable(test[1:,batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "    outputs, hidden, skills, D = model(inputs, None)\n",
    "    preds[:,batch*batch_size:(batch+1)*batch_size] = outputs\n",
    "    A_pred[batch*batch_size:(batch+1)*batch_size,:] = skills \n",
    "    \n",
    "print('RMSE A: {}'.format(rmse_min_max(A_pred.data.numpy(), A_true[(idx_train+idx_val):])))\n",
    "print('RMSE D: {}'.format(rmse_min_max(D.data.numpy(), D_true)))\n",
    "accuracy(preds, test[1:,:])\n",
    "accuracy_last(preds[-1,:], test[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = rank_similarities(A_true[(idx_train+idx_val):], test, A_pred)\n",
    "print(results['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Summary of Ranking Evaluation: \n",
      "        The correlations are with the true rankings derived from A_true.\n",
      "        For the baseline, we get a Kendall Rank correlation of 0.033, with p-value of 0.124, and a Spearman correlation of 0.049, with p-value of 0.125. \n",
      "        For the prediction, we get a Kendall Rank correlation of -0.012, with p-value of 0.558, and a Spearman correlation of -0.019, with p-value of 0.546.  \n",
      "        Which gives us an average difference of -0.0565 versus the baseline. \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "results = rank_similarities(A_true, Yt, train)\n",
    "print(results['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67363352 0.34875009 0.45567222 0.76393018 0.62340218]\n",
      "{0.5, 0.1, 0.3, 0.2, 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.3280)\n",
      "0.48944444444444446\n",
      "RMSE A: 0.41321895522657626\n",
      "RMSE D: 0.46254148619455304\n",
      "10 tensor(0.8601)\n",
      "0.4803131313131313\n",
      "RMSE A: 0.36741722820092293\n",
      "RMSE D: 0.3854353724191575\n",
      "0.4787070707070707\n",
      "done\n",
      "0 tensor(1.9985)\n",
      "0.5032929292929293\n",
      "RMSE A: 0.50919118529673\n",
      "RMSE D: 0.4492963114053607\n",
      "10 tensor(0.8606)\n",
      "0.4785656565656566\n",
      "RMSE A: 0.36756588297951304\n",
      "RMSE D: 0.3713725979540209\n",
      "20 tensor(0.8554)\n",
      "0.48397979797979795\n",
      "RMSE A: 0.3641292753668714\n",
      "RMSE D: 0.42039191691995553\n",
      "0.48597979797979796\n",
      "done\n",
      "0 tensor(1.2593)\n",
      "0.5110707070707071\n",
      "RMSE A: 0.48182128081911146\n",
      "RMSE D: 0.330943770978714\n",
      "0.4784242424242424\n",
      "done\n",
      "0 tensor(2.4409)\n",
      "0.5184444444444445\n",
      "RMSE A: 0.47526985063165056\n",
      "RMSE D: 0.34508595146288723\n",
      "10 tensor(0.8406)\n",
      "0.5003636363636363\n",
      "RMSE A: 0.35819794728253196\n",
      "RMSE D: 0.43959553735739854\n",
      "20 tensor(0.8348)\n",
      "0.5008181818181818\n",
      "RMSE A: 0.3194916266610254\n",
      "RMSE D: 0.4446673889964636\n",
      "0.5054848484848485\n",
      "done\n",
      "0 tensor(1.4675)\n",
      "0.4865959595959596\n",
      "RMSE A: 0.4976868465537525\n",
      "RMSE D: 0.38730298864966994\n",
      "10 tensor(1.0219)\n",
      "0.48315151515151517\n",
      "RMSE A: 0.3733455817524671\n",
      "RMSE D: 0.3331809531785256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b8f2de68fa1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskills\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/irt-explore/inference/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden, steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskills\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mn_skills\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskills\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/irt-explore/inference/models.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, input, i, hidden)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mskills\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mskills\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskills\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mingate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforgetgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Hyperparameter Search\n",
    "n_epochs = 50\n",
    "hidden_size = {512,256,128,64}\n",
    "dropout = np.random.uniform(size=5)\n",
    "print(dropout)\n",
    "num_layers = {32,16,8,4}\n",
    "#l_rate = np.random.uniform(0.01,0.5,5)\n",
    "l_rate = {0.002,0.01,0.05,0.2,0.5}\n",
    "print(l_rate)\n",
    "A_rmse = 1\n",
    "D_rmse = 1\n",
    "max_acc = 0\n",
    "params = {}\n",
    "concepts = np.nonzero(D_true)\n",
    "acc = []\n",
    "h_loss = {}\n",
    "i=0\n",
    "for size in hidden_size:\n",
    "    for drop in dropout:\n",
    "        for layers in num_layers:\n",
    "            for rate in l_rate:\n",
    "                model = models.RNN_Skills_Model(False, concepts, num_concepts, num_questions, size, num_students, layers, drop)\n",
    "                criterion = nn.functional.binary_cross_entropy\n",
    "                optimizer = optim.Adam(model.parameters(), lr=rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "                losses = np.zeros(n_epochs)\n",
    "                \n",
    "                for epoch in range(n_epochs):\n",
    "\n",
    "                    inputs = Variable(Yt[:-1])\n",
    "                    targets = Variable(Yt[1:])\n",
    "\n",
    "                    outputs, hidden, skills, D = model(inputs, None)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    losses[epoch] += loss.data[0]\n",
    "                    \n",
    "                    if epoch>0 and np.abs(losses[epoch]-losses[epoch-1])<0.00005:\n",
    "                        break\n",
    "\n",
    "                    if epoch % 10 == 0:\n",
    "                        print(epoch, loss.data[0])\n",
    "                        print(accuracy(outputs,targets))\n",
    "                        print('RMSE A: {}'.format(rmse_min_max(skills.data.numpy(), A_true)))\n",
    "                        print('RMSE D: {}'.format(rmse_min_max(D.data.numpy(), D_true)))\n",
    "\n",
    "                \n",
    "                print(accuracy(outputs,targets))\n",
    "                if accuracy(outputs,targets)>max_acc:\n",
    "                    params['accuracy'] = (size,drop,layers,rate)\n",
    "                    max_acc = accuracy(outputs,targets)\n",
    "                if rmse_min_max(skills.data.numpy(), A_true)<A_rmse:\n",
    "                    params['A'] = (size,drop,layers,rate)\n",
    "                    A_rmse = rmse_min_max(skills.data.numpy(), A_true)\n",
    "                if rmse_min_max(D.data.numpy(), D_true)<D_rmse:\n",
    "                    params['D'] = (size,drop,layers,rate)\n",
    "                    D_rmse = rmse_min_max(D.data.numpy(), D_true)\n",
    "                acc.append(accuracy(outputs,targets))\n",
    "                h_loss[i] = losses\n",
    "                print('done')\n",
    "                i+=1\n",
    "                    \n",
    "print(params)\n",
    "print(max_acc)\n",
    "print(A_rmse)\n",
    "print(D_rmse)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
