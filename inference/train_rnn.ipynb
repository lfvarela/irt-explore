{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "from permutation_metrics import rank_similarities\n",
    "import utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "Y = torch.tensor(np.load('../datasets/sigmoid_irf_uncorrel.npy'), dtype=dtype)\n",
    "Yt = Y.transpose(0,1)\n",
    "real_data = torch.tensor(np.genfromtxt('../datasets/real_data.csv', delimiter = ','), dtype = dtype)\n",
    "A_true = np.load('../datasets/students_uncorrel.npy')\n",
    "D_true = np.load('../datasets/questions_uncorrel.npy')\n",
    "\n",
    "# We assume we know the relevant concept of each question beforehand\n",
    "concepts = np.nonzero(D_true)\n",
    "num_students, num_concepts = A_true.shape\n",
    "num_questions = D_true.shape[0]\n",
    "guess_prob = 1/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(R_pred, R_true):\n",
    "    R_pred = R_pred.data.numpy()\n",
    "    R_true = R_true.data.numpy()\n",
    "    R_pred_cpy = np.copy(R_pred)\n",
    "    R_pred_cpy[R_pred_cpy > 0.5] = 1\n",
    "    R_pred_cpy[R_pred_cpy <= 0.5] = 0\n",
    "    print(\"Accuracy: {}\".format(np.sum(R_pred_cpy == R_true) / (R_true.shape[0]*R_true.shape[1])))\n",
    "    return np.sum(R_pred_cpy == R_true) / (R_true.shape[0]*R_true.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_last(R_pred, R_true):\n",
    "    R_pred = R_pred.data.numpy()\n",
    "    R_true = R_true.data.numpy()\n",
    "    R_pred_cpy = np.copy(R_pred)\n",
    "    R_pred_cpy[R_pred_cpy > 0.5] = 1\n",
    "    R_pred_cpy[R_pred_cpy <= 0.5] = 0\n",
    "    print(\"Accuracy: {}\".format(np.sum(R_pred_cpy == R_true) / (R_true.shape[0])))\n",
    "    return np.sum(R_pred_cpy == R_true) / (R_true.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_min_max(A,B):\n",
    "    a_norm = (A - A.min())/(A.max()-A.min())\n",
    "    b_norm = (B - B.min())/(B.max()-B.min())\n",
    "    return np.sqrt(np.mean(np.square(a_norm-b_norm))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing to train simulated data set\n",
    "observations = (real_data.transpose(0,1))\n",
    "#observations = Yt\n",
    "idx_train = int(0.7*observations.size()[1])\n",
    "idx_val = int(0.8*observations.size()[1])\n",
    "train = observations[:,:idx_train]\n",
    "val = observations[:,idx_train:idx_val]\n",
    "test = observations[:,idx_val:]\n",
    "idx_test = observations.size()[1] - idx_val\n",
    "idx_val = idx_val-idx_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN to predict students performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "hidden_size = 128\n",
    "layers = 4\n",
    "batch_size = 100 #needs to have idx_train, idx_val, and idx_train as a multiple\n",
    "rate = 0.002\n",
    "dropout = 0.5\n",
    "\n",
    "model = models.RNN_Model(hidden_size, batch_size, layers, dropout)\n",
    "criterion = nn.functional.binary_cross_entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.6935)\n",
      "Accuracy: 0.5069196428571429\n",
      "20 tensor(0.5866)\n",
      "Accuracy: 0.70625\n",
      "40 tensor(0.4788)\n",
      "Accuracy: 0.74375\n",
      "60 tensor(0.5297)\n",
      "Accuracy: 0.7265625\n",
      "80 tensor(0.4069)\n",
      "Accuracy: 0.7816964285714286\n",
      "100 tensor(0.3784)\n",
      "Accuracy: 0.7875\n",
      "120 tensor(0.3377)\n",
      "Accuracy: 0.8296875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-190e059c6692>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#if batch % 2 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training\n",
    "losses = np.zeros(n_epochs) # For plotting\n",
    "num_batches = int(idx_train/batch_size)\n",
    "preds = torch.zeros(train.size()[0]-1,train.size()[1])\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for batch in range(num_batches):\n",
    "        inputs = Variable(train[:-1,batch*batch_size:(batch+1)*batch_size])\n",
    "        targets = Variable(train[1:,batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "        outputs, hidden = model(inputs, None)\n",
    "        preds[:,batch*batch_size:(batch+1)*batch_size] = outputs\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #if batch % 2 == 0:\n",
    "            #print(\"Batch Done\")\n",
    "    if epoch % 20 == 0:\n",
    "        losses[epoch] += loss.data[0]\n",
    "        print(epoch, loss.data[0])\n",
    "        accuracy(preds, train[1:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6125"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation\n",
    "num_batches = int(idx_val/batch_size)\n",
    "preds = torch.zeros(val.size()[0]-1,val.size()[1])\n",
    "\n",
    "for batch in range(num_batches):\n",
    "    inputs = Variable(val[:-1,batch*batch_size:(batch+1)*batch_size])\n",
    "    targets = Variable(val[1:,batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "    outputs, hidden = model(inputs, None)\n",
    "    preds[:,batch*batch_size:(batch+1)*batch_size] = outputs\n",
    "    \n",
    "accuracy(preds, val[1:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "num_batches = int(idx_test/batch_size)\n",
    "preds = torch.zeros(test.size()[0]-1,test.size()[1])\n",
    "\n",
    "for batch in range(num_batches):\n",
    "    inputs = Variable(test[:-1,batch*batch_size:(batch+1)*batch_size])\n",
    "    targets = Variable(test[1:,batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "    outputs, hidden = model(inputs, None)\n",
    "    preds[:,batch*batch_size:(batch+1)*batch_size] = outputs\n",
    "\n",
    "accuracy(preds, test[1:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skill RNN to predict students performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "batch_size = 80\n",
    "average = True\n",
    "sigmoid = True\n",
    "concepts = ([0,1,2,3,4,5,6,7,8],[0,0,0,0,0,0,0,0,0]) #use for real data\n",
    "num_questions = observations.size()[0] #use for real data\n",
    "hidden_size = 128\n",
    "dropout = 0.3\n",
    "num_layers = 4\n",
    "rate = 0.002\n",
    "\n",
    "model = models.RNN_Skills_Model(average, concepts, num_concepts, num_questions, hidden_size, batch_size, num_layers, dropout, sigmoid)\n",
    "criterion = nn.functional.binary_cross_entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.6815)\n",
      "Accuracy: 0.5183035714285714\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.5875\n",
      "20 tensor(0.6362)\n",
      "Accuracy: 0.5183035714285714\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.5875\n",
      "40 tensor(0.6084)\n",
      "Accuracy: 0.5183035714285714\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.5875\n",
      "60 tensor(0.5858)\n",
      "Accuracy: 0.5428571428571428\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.6296875\n",
      "80 tensor(0.5675)\n",
      "Accuracy: 0.6743303571428572\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.6875\n",
      "100 tensor(0.5515)\n",
      "Accuracy: 0.6979910714285714\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.69375\n",
      "120 tensor(0.5357)\n",
      "Accuracy: 0.7296875\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.690625\n",
      "140 tensor(0.5228)\n",
      "Accuracy: 0.7589285714285714\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.6875\n",
      "160 tensor(0.5138)\n",
      "Accuracy: 0.7649553571428571\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.6921875\n",
      "180 tensor(0.5079)\n",
      "Accuracy: 0.7680803571428572\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.6984375\n",
      "200 tensor(0.5067)\n",
      "Accuracy: 0.7767857142857143\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.69375\n",
      "220 tensor(0.5014)\n",
      "Accuracy: 0.7888392857142857\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.696875\n",
      "240 tensor(0.4975)\n",
      "Accuracy: 0.7988839285714285\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.684375\n",
      "260 tensor(0.4943)\n",
      "Accuracy: 0.8042410714285714\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.684375\n",
      "280 tensor(0.4913)\n",
      "Accuracy: 0.8078125\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.684375\n",
      "300 tensor(0.4901)\n",
      "Accuracy: 0.8102678571428571\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.6859375\n",
      "320 tensor(0.4880)\n",
      "Accuracy: 0.8100446428571428\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.678125\n",
      "340 tensor(0.4883)\n",
      "Accuracy: 0.8133928571428571\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.7\n",
      "360 tensor(0.4881)\n",
      "Accuracy: 0.8151785714285714\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.684375\n",
      "380 tensor(0.4883)\n",
      "Accuracy: 0.8196428571428571\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.684375\n",
      "400 tensor(0.4855)\n",
      "Accuracy: 0.8229910714285714\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.684375\n",
      "420 tensor(0.4851)\n",
      "Accuracy: 0.8261160714285715\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.6765625\n",
      "440 tensor(0.4842)\n",
      "Accuracy: 0.8303571428571429\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.678125\n",
      "460 tensor(0.4832)\n",
      "Accuracy: 0.8296875\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.675\n",
      "480 tensor(0.4836)\n",
      "Accuracy: 0.8292410714285714\n",
      "Validation\n",
      "Accuracy: 0.7625\n",
      "Accuracy: 0.6734375\n",
      "Accuracy: 0.8274553571428571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8274553571428571"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training\n",
    "losses = np.zeros(n_epochs) # For plotting\n",
    "num_batches = int(idx_train/batch_size)\n",
    "preds = torch.zeros(train.size()[0]-1,train.size()[1])\n",
    "A_pred = torch.zeros(train.size()[1],num_concepts)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    num_batches = int(idx_train/batch_size)\n",
    "    preds = torch.zeros(train.size()[0]-1,train.size()[1])\n",
    "    A_pred = torch.zeros(train.size()[1],num_concepts)\n",
    "    for batch in range(num_batches):\n",
    "        inputs = Variable(train[:-1,batch*batch_size:(batch+1)*batch_size])\n",
    "        targets = Variable(train[1:,batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "        outputs, hidden, skills, D = model(inputs, None)\n",
    "        preds[:,batch*batch_size:(batch+1)*batch_size] = outputs\n",
    "        A_pred[batch*batch_size:(batch+1)*batch_size,:] = skills \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    losses[epoch] += loss.data[0]\n",
    "    \n",
    "    \n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(epoch, loss.data[0])\n",
    "        accuracy(preds,train[1:,:])\n",
    "        #print('RMSE A: {}'.format(rmse_min_max(A_pred.data.numpy(), A_true[:idx_train])))\n",
    "        #print('RMSE D: {}'.format(rmse_min_max(D.data.numpy(), D_true)))\n",
    "        \n",
    "        print(\"Validation\")\n",
    "        num_batches = int(idx_val/batch_size)\n",
    "        preds = torch.zeros(val.size()[0]-1,val.size()[1])\n",
    "        A_pred_val = torch.zeros(val.size()[1],num_concepts)\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            inputs = Variable(val[:-1,batch*batch_size:(batch+1)*batch_size])\n",
    "            targets = Variable(val[1:,batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "            outputs, hidden, skills, D = model(inputs, None)\n",
    "            preds[:,batch*batch_size:(batch+1)*batch_size] = outputs\n",
    "            A_pred_val[batch*batch_size:(batch+1)*batch_size,:] = skills \n",
    "\n",
    "        accuracy_last(preds[-1,:], val[-1,:])\n",
    "        accuracy(preds, val[1:,:])\n",
    "        #print('RMSE A: {}'.format(rmse_min_max(A_pred_val.data.numpy(), A_true[idx_train:(idx_train+idx_val)])))\n",
    "        #print('RMSE D: {}'.format(rmse_min_max(D.data.numpy(), D_true)))\n",
    "        \n",
    "accuracy(preds,train[1:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-f375ddc2b48f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#print(len(np.unique(train[1:,:].detach().numpy())))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#print(train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    275\u001b[0m     return _average_binary_score(\n\u001b[1;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0my_score_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnot_average_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         score[c] = binary_metric(y_true_c, y_score_c,\n\u001b[0;32m--> 118\u001b[0;31m                                  sample_weight=score_weight)\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m# Average the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    269\u001b[0m                              \"is not defined in that case.\")\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "#print(len(np.unique(train[1:,:].detach().numpy())))\n",
    "#print(train)\n",
    "sklearn.metrics.roc_auc_score(train[1:,:].detach().numpy(),preds.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Summary of Ranking Evaluation: \n",
      "    Correlations with true rankings derived from A_true.\n",
      "        Baseline: \n",
      "            Kendall:-0.015 (p-value 0.624)\n",
      "            Spearman: -0.021 (p-value 0.616) \n",
      "            \n",
      "        Prediction:\n",
      "            Kendall: -0.011 (p-value 0.702)\n",
      "            Spearman: -0.015 (p-value 0.725)  \n",
      "            \n",
      "    Average difference: 0.005 (absolute diff., vs. the baseline) \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "results = rank_similarities(A_true[:idx_train],train.transpose(0,1).data.numpy(), A_pred.data.numpy())\n",
    "print(results['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6828125\n",
      "Accuracy: 0.7625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7625"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation\n",
    "num_batches = int(idx_val/batch_size)\n",
    "preds = torch.zeros(val.size()[0]-1,val.size()[1])\n",
    "A_pred = torch.zeros(val.size()[1],num_concepts)\n",
    "\n",
    "for batch in range(num_batches):\n",
    "    inputs = Variable(val[:-1,batch*batch_size:(batch+1)*batch_size])\n",
    "    targets = Variable(val[1:,batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "    outputs, hidden, skills, D = model(inputs, None)\n",
    "    preds[:,batch*batch_size:(batch+1)*batch_size] = outputs\n",
    "    A_pred[batch*batch_size:(batch+1)*batch_size,:] = skills \n",
    "    \n",
    "#print('RMSE A: {}'.format(rmse_min_max(A_pred.data.numpy(), A_true[idx_train:(idx_train+idx_val)])))\n",
    "#print('RMSE D: {}'.format(rmse_min_max(D.data.numpy(), D_true)))\n",
    "accuracy(preds, val[1:,:])\n",
    "accuracy_last(preds[-1,:], val[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6984375\n",
      "Accuracy: 0.76875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76875"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "num_batches = int(idx_test/batch_size)\n",
    "preds = torch.zeros(test.size()[0]-1,test.size()[1])\n",
    "A_pred = torch.zeros(test.size()[1],num_concepts)\n",
    "\n",
    "for batch in range(num_batches):\n",
    "    inputs = Variable(test[:-1,batch*batch_size:(batch+1)*batch_size])\n",
    "    targets = Variable(test[1:,batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "    outputs, hidden, skills, D = model(inputs, None)\n",
    "    preds[:,batch*batch_size:(batch+1)*batch_size] = outputs\n",
    "    A_pred[batch*batch_size:(batch+1)*batch_size,:] = skills \n",
    "    \n",
    "#print('RMSE A: {}'.format(rmse_min_max(A_pred.data.numpy(), A_true[(idx_train+idx_val):])))\n",
    "#print('RMSE D: {}'.format(rmse_min_max(D.data.numpy(), D_true)))\n",
    "accuracy(preds, test[1:,:])\n",
    "accuracy_last(preds[-1,:], test[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Summary of Ranking Evaluation: \n",
      "    Correlations with true rankings derived from A_true.\n",
      "        Baseline: \n",
      "            Kendall:0.706 (p-value 0.0)\n",
      "            Spearman: 0.88 (p-value 0.0) \n",
      "            \n",
      "        Prediction:\n",
      "            Kendall: 0.02 (p-value 0.671)\n",
      "            Spearman: 0.029 (p-value 0.68)  \n",
      "            \n",
      "    Average difference: -0.768 (absolute diff., vs. the baseline) \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "results = rank_similarities(A_true[(idx_train+idx_val):], test.transpose(0,1).data.numpy(), A_pred.data.numpy())\n",
    "print(results['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Summary of Ranking Evaluation: \n",
      "        The correlations are with the true rankings derived from A_true.\n",
      "        For the baseline, we get a Kendall Rank correlation of 0.033, with p-value of 0.124, and a Spearman correlation of 0.049, with p-value of 0.125. \n",
      "        For the prediction, we get a Kendall Rank correlation of -0.012, with p-value of 0.558, and a Spearman correlation of -0.019, with p-value of 0.546.  \n",
      "        Which gives us an average difference of -0.0565 versus the baseline. \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "results = rank_similarities(A_true, Yt, train)\n",
    "print(results['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67363352 0.34875009 0.45567222 0.76393018 0.62340218]\n",
      "{0.5, 0.1, 0.3, 0.2, 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.3280)\n",
      "0.48944444444444446\n",
      "RMSE A: 0.41321895522657626\n",
      "RMSE D: 0.46254148619455304\n",
      "10 tensor(0.8601)\n",
      "0.4803131313131313\n",
      "RMSE A: 0.36741722820092293\n",
      "RMSE D: 0.3854353724191575\n",
      "0.4787070707070707\n",
      "done\n",
      "0 tensor(1.9985)\n",
      "0.5032929292929293\n",
      "RMSE A: 0.50919118529673\n",
      "RMSE D: 0.4492963114053607\n",
      "10 tensor(0.8606)\n",
      "0.4785656565656566\n",
      "RMSE A: 0.36756588297951304\n",
      "RMSE D: 0.3713725979540209\n",
      "20 tensor(0.8554)\n",
      "0.48397979797979795\n",
      "RMSE A: 0.3641292753668714\n",
      "RMSE D: 0.42039191691995553\n",
      "0.48597979797979796\n",
      "done\n",
      "0 tensor(1.2593)\n",
      "0.5110707070707071\n",
      "RMSE A: 0.48182128081911146\n",
      "RMSE D: 0.330943770978714\n",
      "0.4784242424242424\n",
      "done\n",
      "0 tensor(2.4409)\n",
      "0.5184444444444445\n",
      "RMSE A: 0.47526985063165056\n",
      "RMSE D: 0.34508595146288723\n",
      "10 tensor(0.8406)\n",
      "0.5003636363636363\n",
      "RMSE A: 0.35819794728253196\n",
      "RMSE D: 0.43959553735739854\n",
      "20 tensor(0.8348)\n",
      "0.5008181818181818\n",
      "RMSE A: 0.3194916266610254\n",
      "RMSE D: 0.4446673889964636\n",
      "0.5054848484848485\n",
      "done\n",
      "0 tensor(1.4675)\n",
      "0.4865959595959596\n",
      "RMSE A: 0.4976868465537525\n",
      "RMSE D: 0.38730298864966994\n",
      "10 tensor(1.0219)\n",
      "0.48315151515151517\n",
      "RMSE A: 0.3733455817524671\n",
      "RMSE D: 0.3331809531785256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b8f2de68fa1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskills\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/irt-explore/inference/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden, steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskills\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mn_skills\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskills\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/irt-explore/inference/models.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, input, i, hidden)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mskills\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mskills\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskills\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mingate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforgetgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Hyperparameter Search\n",
    "n_epochs = 50\n",
    "hidden_size = {512,256,128,64}\n",
    "dropout = np.random.uniform(size=5)\n",
    "print(dropout)\n",
    "num_layers = {32,16,8,4}\n",
    "#l_rate = np.random.uniform(0.01,0.5,5)\n",
    "l_rate = {0.002,0.01,0.05,0.2,0.5}\n",
    "print(l_rate)\n",
    "A_rmse = 1\n",
    "D_rmse = 1\n",
    "max_acc = 0\n",
    "params = {}\n",
    "concepts = np.nonzero(D_true)\n",
    "acc = []\n",
    "h_loss = {}\n",
    "i=0\n",
    "for size in hidden_size:\n",
    "    for drop in dropout:\n",
    "        for layers in num_layers:\n",
    "            for rate in l_rate:\n",
    "                model = models.RNN_Skills_Model(False, concepts, num_concepts, num_questions, size, num_students, layers, drop)\n",
    "                criterion = nn.functional.binary_cross_entropy\n",
    "                optimizer = optim.Adam(model.parameters(), lr=rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "                losses = np.zeros(n_epochs)\n",
    "                \n",
    "                for epoch in range(n_epochs):\n",
    "\n",
    "                    inputs = Variable(Yt[:-1])\n",
    "                    targets = Variable(Yt[1:])\n",
    "\n",
    "                    outputs, hidden, skills, D = model(inputs, None)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    losses[epoch] += loss.data[0]\n",
    "                    \n",
    "                    if epoch>0 and np.abs(losses[epoch]-losses[epoch-1])<0.00005:\n",
    "                        break\n",
    "\n",
    "                    if epoch % 10 == 0:\n",
    "                        print(epoch, loss.data[0])\n",
    "                        print(accuracy(outputs,targets))\n",
    "                        print('RMSE A: {}'.format(rmse_min_max(skills.data.numpy(), A_true)))\n",
    "                        print('RMSE D: {}'.format(rmse_min_max(D.data.numpy(), D_true)))\n",
    "\n",
    "                \n",
    "                print(accuracy(outputs,targets))\n",
    "                if accuracy(outputs,targets)>max_acc:\n",
    "                    params['accuracy'] = (size,drop,layers,rate)\n",
    "                    max_acc = accuracy(outputs,targets)\n",
    "                if rmse_min_max(skills.data.numpy(), A_true)<A_rmse:\n",
    "                    params['A'] = (size,drop,layers,rate)\n",
    "                    A_rmse = rmse_min_max(skills.data.numpy(), A_true)\n",
    "                if rmse_min_max(D.data.numpy(), D_true)<D_rmse:\n",
    "                    params['D'] = (size,drop,layers,rate)\n",
    "                    D_rmse = rmse_min_max(D.data.numpy(), D_true)\n",
    "                acc.append(accuracy(outputs,targets))\n",
    "                h_loss[i] = losses\n",
    "                print('done')\n",
    "                i+=1\n",
    "                    \n",
    "print(params)\n",
    "print(max_acc)\n",
    "print(A_rmse)\n",
    "print(D_rmse)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
