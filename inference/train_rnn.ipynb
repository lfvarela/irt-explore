{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "import utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "Y = torch.tensor(np.load('../datasets/floored_exp_uncorrel.npy'), dtype=dtype)\n",
    "A_true = np.load('../datasets/students_uncorrel.npy')\n",
    "D_true = np.load('../datasets/questions_uncorrel.npy')\n",
    "# We assume we know the relevant concept of each question beforehand\n",
    "concepts = np.nonzero(D_true)\n",
    "num_students, num_concepts = A_true.shape\n",
    "num_questions = D_true.shape[0]\n",
    "guess_prob = 1/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(R_pred, R_true):\n",
    "    R_pred = R_pred.data.numpy()\n",
    "    R_true = R_true.data.numpy()\n",
    "    R_pred_cpy = np.copy(R_pred)\n",
    "    R_pred_cpy[R_pred_cpy > 0.5] = 1\n",
    "    R_pred_cpy[R_pred_cpy <= 0.5] = 0\n",
    "    print(\"Accuracy: {}\".format(np.sum(R_pred_cpy == R_true) / (R_true.shape[0]*R_true.shape[1])))\n",
    "    return np.sum(R_pred_cpy == R_true) / (R_true.shape[0]*R_true.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_min_max(A,B):\n",
    "    a_norm = (A - A.min())/(A.max()-A.min())\n",
    "    b_norm = (B - B.min())/(B.max()-B.min())\n",
    "    return np.sqrt(np.mean(np.square(a_norm-b_norm))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yt = Y.transpose(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Simple RNN to predict students performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3000\n",
    "hidden_size = 128\n",
    "\n",
    "model = models.RNN_Model(hidden_size, num_layers=8)\n",
    "criterion = nn.functional.binary_cross_entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.6939)\n",
      "Accuracy: 0.49714141414141416\n",
      "20 tensor(0.6272)\n",
      "Accuracy: 0.6494545454545455\n",
      "40 tensor(0.6243)\n",
      "Accuracy: 0.6517575757575758\n",
      "60 tensor(0.6240)\n",
      "Accuracy: 0.6521111111111111\n",
      "80 tensor(0.6232)\n",
      "Accuracy: 0.6525252525252525\n",
      "100 tensor(0.6212)\n",
      "Accuracy: 0.6534545454545454\n",
      "120 tensor(0.6178)\n",
      "Accuracy: 0.6548282828282829\n",
      "140 tensor(0.6125)\n",
      "Accuracy: 0.659060606060606\n",
      "160 tensor(0.6068)\n",
      "Accuracy: 0.6636969696969697\n",
      "180 tensor(0.6009)\n",
      "Accuracy: 0.6687070707070707\n",
      "200 tensor(0.5945)\n",
      "Accuracy: 0.6750101010101011\n",
      "220 tensor(0.5879)\n",
      "Accuracy: 0.6809292929292929\n",
      "240 tensor(0.5821)\n",
      "Accuracy: 0.6856464646464646\n",
      "260 tensor(0.5776)\n",
      "Accuracy: 0.688949494949495\n",
      "280 tensor(0.5733)\n",
      "Accuracy: 0.691949494949495\n",
      "300 tensor(0.5700)\n",
      "Accuracy: 0.6933838383838384\n",
      "320 tensor(0.5651)\n",
      "Accuracy: 0.6976969696969697\n",
      "340 tensor(0.5619)\n",
      "Accuracy: 0.7003333333333334\n",
      "360 tensor(0.5573)\n",
      "Accuracy: 0.702929292929293\n",
      "380 tensor(0.5530)\n",
      "Accuracy: 0.705060606060606\n",
      "400 tensor(0.5474)\n",
      "Accuracy: 0.7094747474747475\n",
      "420 tensor(0.5436)\n",
      "Accuracy: 0.7112323232323232\n",
      "440 tensor(0.5411)\n",
      "Accuracy: 0.7110808080808081\n",
      "460 tensor(0.5379)\n",
      "Accuracy: 0.7143636363636363\n",
      "480 tensor(0.5308)\n",
      "Accuracy: 0.7181818181818181\n",
      "500 tensor(0.5281)\n",
      "Accuracy: 0.719050505050505\n",
      "520 tensor(0.5167)\n",
      "Accuracy: 0.7256868686868687\n",
      "540 tensor(0.5107)\n",
      "Accuracy: 0.7317878787878788\n",
      "560 tensor(0.5066)\n",
      "Accuracy: 0.7323030303030303\n",
      "580 tensor(0.4982)\n",
      "Accuracy: 0.7386262626262626\n",
      "600 tensor(0.4958)\n",
      "Accuracy: 0.7393737373737373\n",
      "620 tensor(0.4855)\n",
      "Accuracy: 0.7488080808080808\n",
      "640 tensor(0.4830)\n",
      "Accuracy: 0.7481414141414141\n",
      "660 tensor(0.4736)\n",
      "Accuracy: 0.7552525252525253\n",
      "680 tensor(0.4717)\n",
      "Accuracy: 0.7582525252525253\n",
      "700 tensor(0.4807)\n",
      "Accuracy: 0.7513737373737374\n",
      "720 tensor(0.6215)\n",
      "Accuracy: 0.6549191919191919\n",
      "740 tensor(0.5595)\n",
      "Accuracy: 0.7023232323232323\n",
      "760 tensor(0.5414)\n",
      "Accuracy: 0.7133333333333334\n",
      "780 tensor(0.4981)\n",
      "Accuracy: 0.741030303030303\n",
      "800 tensor(0.4808)\n",
      "Accuracy: 0.752020202020202\n",
      "820 tensor(0.4717)\n",
      "Accuracy: 0.7587979797979798\n",
      "840 tensor(0.4747)\n",
      "Accuracy: 0.7563838383838384\n",
      "860 tensor(0.4590)\n",
      "Accuracy: 0.7679393939393939\n",
      "880 tensor(0.4467)\n",
      "Accuracy: 0.7773636363636364\n",
      "900 tensor(0.4450)\n",
      "Accuracy: 0.7771010101010101\n",
      "920 tensor(0.4304)\n",
      "Accuracy: 0.7895454545454546\n",
      "940 tensor(0.4241)\n",
      "Accuracy: 0.792989898989899\n",
      "960 tensor(0.4278)\n",
      "Accuracy: 0.790010101010101\n",
      "980 tensor(0.4175)\n",
      "Accuracy: 0.7972929292929293\n",
      "1000 tensor(0.4050)\n",
      "Accuracy: 0.8057676767676768\n",
      "1020 tensor(0.4032)\n",
      "Accuracy: 0.8053939393939394\n",
      "1040 tensor(0.3929)\n",
      "Accuracy: 0.8142020202020201\n",
      "1060 tensor(0.3859)\n",
      "Accuracy: 0.8182121212121212\n",
      "1080 tensor(0.3873)\n",
      "Accuracy: 0.8166060606060606\n",
      "1100 tensor(0.3792)\n",
      "Accuracy: 0.820939393939394\n",
      "1120 tensor(0.3772)\n",
      "Accuracy: 0.8228787878787879\n",
      "1140 tensor(0.3614)\n",
      "Accuracy: 0.8325555555555556\n",
      "1160 tensor(0.3569)\n",
      "Accuracy: 0.8335858585858585\n",
      "1180 tensor(0.3553)\n",
      "Accuracy: 0.8361010101010101\n",
      "1200 tensor(0.3467)\n",
      "Accuracy: 0.8413737373737373\n",
      "1220 tensor(0.3395)\n",
      "Accuracy: 0.8454141414141414\n",
      "1240 tensor(0.3356)\n",
      "Accuracy: 0.8483030303030303\n",
      "1260 tensor(0.3232)\n",
      "Accuracy: 0.8548686868686869\n",
      "1280 tensor(0.3198)\n",
      "Accuracy: 0.8570909090909091\n",
      "1300 tensor(0.3110)\n",
      "Accuracy: 0.8613131313131314\n",
      "1320 tensor(0.3038)\n",
      "Accuracy: 0.866030303030303\n",
      "1340 tensor(0.3011)\n",
      "Accuracy: 0.8654747474747475\n",
      "1360 tensor(0.2907)\n",
      "Accuracy: 0.8728888888888889\n",
      "1380 tensor(0.2860)\n",
      "Accuracy: 0.8749191919191919\n",
      "1400 tensor(0.2760)\n",
      "Accuracy: 0.8814545454545455\n",
      "1420 tensor(0.2689)\n",
      "Accuracy: 0.8862323232323233\n",
      "1440 tensor(0.2617)\n",
      "Accuracy: 0.8894343434343435\n",
      "1460 tensor(0.2577)\n",
      "Accuracy: 0.8923232323232323\n",
      "1480 tensor(0.2574)\n",
      "Accuracy: 0.892080808080808\n",
      "1500 tensor(0.2459)\n",
      "Accuracy: 0.8985050505050505\n",
      "1520 tensor(0.2309)\n",
      "Accuracy: 0.9085858585858586\n",
      "1540 tensor(0.2235)\n",
      "Accuracy: 0.9123434343434343\n",
      "1560 tensor(0.2179)\n",
      "Accuracy: 0.9143838383838384\n",
      "1580 tensor(0.2188)\n",
      "Accuracy: 0.914010101010101\n",
      "1600 tensor(0.2052)\n",
      "Accuracy: 0.922939393939394\n",
      "1620 tensor(0.1975)\n",
      "Accuracy: 0.9261818181818182\n",
      "1640 tensor(0.1909)\n",
      "Accuracy: 0.929949494949495\n",
      "1660 tensor(0.1831)\n",
      "Accuracy: 0.9345656565656566\n",
      "1680 tensor(0.1771)\n",
      "Accuracy: 0.937969696969697\n",
      "1700 tensor(0.1694)\n",
      "Accuracy: 0.9418383838383838\n",
      "1720 tensor(0.1632)\n",
      "Accuracy: 0.9458585858585858\n",
      "1740 tensor(0.1566)\n",
      "Accuracy: 0.9485555555555556\n",
      "1760 tensor(0.1498)\n",
      "Accuracy: 0.9526666666666667\n",
      "1780 tensor(0.1450)\n",
      "Accuracy: 0.954969696969697\n",
      "1800 tensor(0.1385)\n",
      "Accuracy: 0.958949494949495\n",
      "1820 tensor(0.1320)\n",
      "Accuracy: 0.9625151515151515\n",
      "1840 tensor(0.1262)\n",
      "Accuracy: 0.9653838383838383\n",
      "1860 tensor(0.1202)\n",
      "Accuracy: 0.9675555555555555\n",
      "1880 tensor(0.1135)\n",
      "Accuracy: 0.9716868686868687\n",
      "1900 tensor(0.1077)\n",
      "Accuracy: 0.9743333333333334\n",
      "1920 tensor(0.1024)\n",
      "Accuracy: 0.9772929292929293\n",
      "1940 tensor(0.0971)\n",
      "Accuracy: 0.9797272727272728\n",
      "1960 tensor(0.0923)\n",
      "Accuracy: 0.9815757575757575\n",
      "1980 tensor(0.0865)\n",
      "Accuracy: 0.985\n",
      "2000 tensor(0.0812)\n",
      "Accuracy: 0.9875656565656565\n",
      "2020 tensor(0.0763)\n",
      "Accuracy: 0.9896262626262626\n",
      "2040 tensor(0.0717)\n",
      "Accuracy: 0.9916262626262626\n",
      "2060 tensor(0.0671)\n",
      "Accuracy: 0.9935454545454545\n",
      "2080 tensor(0.0631)\n",
      "Accuracy: 0.9948080808080808\n",
      "2100 tensor(0.0591)\n",
      "Accuracy: 0.99589898989899\n",
      "2120 tensor(0.0558)\n",
      "Accuracy: 0.9968484848484849\n",
      "2140 tensor(0.0526)\n",
      "Accuracy: 0.9976060606060606\n",
      "2160 tensor(0.0496)\n",
      "Accuracy: 0.9981010101010102\n",
      "2180 tensor(0.0467)\n",
      "Accuracy: 0.9987676767676767\n",
      "2200 tensor(0.0440)\n",
      "Accuracy: 0.9991717171717172\n",
      "2220 tensor(0.0417)\n",
      "Accuracy: 0.9993030303030302\n",
      "2240 tensor(0.0392)\n",
      "Accuracy: 0.9996969696969698\n",
      "2260 tensor(0.0372)\n",
      "Accuracy: 0.9997777777777778\n",
      "2280 tensor(0.0352)\n",
      "Accuracy: 0.9998686868686869\n",
      "2300 tensor(0.0335)\n",
      "Accuracy: 0.9999191919191919\n",
      "2320 tensor(0.0317)\n",
      "Accuracy: 0.9999292929292929\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e0d2af7be958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = np.zeros(n_epochs) # For plotting\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    inputs = Variable(Yt[:-1])\n",
    "    targets = Variable(Yt[1:])\n",
    "\n",
    "    outputs, hidden = model(inputs, None)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses[epoch] += loss.data[0]\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(epoch, loss.data[0])\n",
    "        accuracy(outputs,targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Skill RNN to predict students performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3000\n",
    "hidden_size = 128\n",
    "dropout = 0.2\n",
    "num_layers = 8\n",
    "average = True\n",
    "sigmoid = False\n",
    "\n",
    "concepts = np.nonzero(D_true)\n",
    "model = models.RNN_Skills_Model(average, concepts, num_concepts, num_questions, hidden_size, num_students, num_layers, dropout, sigmoid)\n",
    "criterion = nn.functional.binary_cross_entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.8247)\n",
      "Accuracy: 0.5113333333333333\n",
      "RMSE A: 0.30150626692352633\n",
      "RMSE D: 0.3110942077766168\n",
      "20 tensor(0.8247)\n",
      "Accuracy: 0.5113333333333333\n",
      "RMSE A: 0.30279388112519023\n",
      "RMSE D: 0.3110942077766168\n",
      "40 tensor(0.8247)\n",
      "Accuracy: 0.5113333333333333\n",
      "RMSE A: 0.30141495837589816\n",
      "RMSE D: 0.3110942077766168\n",
      "60 tensor(0.8247)\n",
      "Accuracy: 0.5113333333333333\n",
      "RMSE A: 0.30250240916832477\n",
      "RMSE D: 0.3110942077766168\n",
      "80 tensor(0.8247)\n",
      "Accuracy: 0.5113333333333333\n",
      "RMSE A: 0.3008059640369871\n",
      "RMSE D: 0.3110942077766168\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0c6681c691be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = np.zeros(n_epochs) # For plotting\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    inputs = Variable(Yt[:-1])\n",
    "    targets = Variable(Yt[1:])\n",
    "\n",
    "    outputs, hidden, skills, D = model(inputs, None)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses[epoch] += loss.data[0]\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(epoch, loss.data[0])\n",
    "        accuracy(outputs,targets)\n",
    "        print('RMSE A: {}'.format(rmse_min_max(skills.data.numpy(), A_true)))\n",
    "        print('RMSE D: {}'.format(rmse_min_max(D.data.numpy(), D_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67363352 0.34875009 0.45567222 0.76393018 0.62340218]\n",
      "{0.5, 0.1, 0.3, 0.2, 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/juasarmiento10/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.3280)\n",
      "0.48944444444444446\n",
      "RMSE A: 0.41321895522657626\n",
      "RMSE D: 0.46254148619455304\n",
      "10 tensor(0.8601)\n",
      "0.4803131313131313\n",
      "RMSE A: 0.36741722820092293\n",
      "RMSE D: 0.3854353724191575\n",
      "0.4787070707070707\n",
      "done\n",
      "0 tensor(1.9985)\n",
      "0.5032929292929293\n",
      "RMSE A: 0.50919118529673\n",
      "RMSE D: 0.4492963114053607\n",
      "10 tensor(0.8606)\n",
      "0.4785656565656566\n",
      "RMSE A: 0.36756588297951304\n",
      "RMSE D: 0.3713725979540209\n",
      "20 tensor(0.8554)\n",
      "0.48397979797979795\n",
      "RMSE A: 0.3641292753668714\n",
      "RMSE D: 0.42039191691995553\n",
      "0.48597979797979796\n",
      "done\n",
      "0 tensor(1.2593)\n",
      "0.5110707070707071\n",
      "RMSE A: 0.48182128081911146\n",
      "RMSE D: 0.330943770978714\n",
      "0.4784242424242424\n",
      "done\n",
      "0 tensor(2.4409)\n",
      "0.5184444444444445\n",
      "RMSE A: 0.47526985063165056\n",
      "RMSE D: 0.34508595146288723\n",
      "10 tensor(0.8406)\n",
      "0.5003636363636363\n",
      "RMSE A: 0.35819794728253196\n",
      "RMSE D: 0.43959553735739854\n",
      "20 tensor(0.8348)\n",
      "0.5008181818181818\n",
      "RMSE A: 0.3194916266610254\n",
      "RMSE D: 0.4446673889964636\n",
      "0.5054848484848485\n",
      "done\n",
      "0 tensor(1.4675)\n",
      "0.4865959595959596\n",
      "RMSE A: 0.4976868465537525\n",
      "RMSE D: 0.38730298864966994\n",
      "10 tensor(1.0219)\n",
      "0.48315151515151517\n",
      "RMSE A: 0.3733455817524671\n",
      "RMSE D: 0.3331809531785256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b8f2de68fa1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskills\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/irt-explore/inference/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden, steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskills\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mn_skills\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskills\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/irt-explore/inference/models.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, input, i, hidden)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mskills\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mskills\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskills\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mingate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforgetgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Hyperparameter Search\n",
    "n_epochs = 50\n",
    "hidden_size = {512,256,128,64}\n",
    "dropout = np.random.uniform(size=5)\n",
    "print(dropout)\n",
    "num_layers = {32,16,8,4}\n",
    "#l_rate = np.random.uniform(0.01,0.5,5)\n",
    "l_rate = {0.002,0.01,0.05,0.2,0.5}\n",
    "print(l_rate)\n",
    "A_rmse = 1\n",
    "D_rmse = 1\n",
    "max_acc = 0\n",
    "params = {}\n",
    "concepts = np.nonzero(D_true)\n",
    "acc = []\n",
    "h_loss = {}\n",
    "i=0\n",
    "for size in hidden_size:\n",
    "    for drop in dropout:\n",
    "        for layers in num_layers:\n",
    "            for rate in l_rate:\n",
    "                model = models.RNN_Skills_Model(False, concepts, num_concepts, num_questions, size, num_students, layers, drop)\n",
    "                criterion = nn.functional.binary_cross_entropy\n",
    "                optimizer = optim.Adam(model.parameters(), lr=rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "                losses = np.zeros(n_epochs)\n",
    "                \n",
    "                for epoch in range(n_epochs):\n",
    "\n",
    "                    inputs = Variable(Yt[:-1])\n",
    "                    targets = Variable(Yt[1:])\n",
    "\n",
    "                    outputs, hidden, skills, D = model(inputs, None)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    losses[epoch] += loss.data[0]\n",
    "                    \n",
    "                    if epoch>0 and np.abs(losses[epoch]-losses[epoch-1])<0.00005:\n",
    "                        break\n",
    "\n",
    "                    if epoch % 10 == 0:\n",
    "                        print(epoch, loss.data[0])\n",
    "                        print(accuracy(outputs,targets))\n",
    "                        print('RMSE A: {}'.format(rmse_min_max(skills.data.numpy(), A_true)))\n",
    "                        print('RMSE D: {}'.format(rmse_min_max(D.data.numpy(), D_true)))\n",
    "\n",
    "                \n",
    "                print(accuracy(outputs,targets))\n",
    "                if accuracy(outputs,targets)>max_acc:\n",
    "                    params['accuracy'] = (size,drop,layers,rate)\n",
    "                    max_acc = accuracy(outputs,targets)\n",
    "                if rmse_min_max(skills.data.numpy(), A_true)<A_rmse:\n",
    "                    params['A'] = (size,drop,layers,rate)\n",
    "                    A_rmse = rmse_min_max(skills.data.numpy(), A_true)\n",
    "                if rmse_min_max(D.data.numpy(), D_true)<D_rmse:\n",
    "                    params['D'] = (size,drop,layers,rate)\n",
    "                    D_rmse = rmse_min_max(D.data.numpy(), D_true)\n",
    "                acc.append(accuracy(outputs,targets))\n",
    "                h_loss[i] = losses\n",
    "                print('done')\n",
    "                i+=1\n",
    "                    \n",
    "print(params)\n",
    "print(max_acc)\n",
    "print(A_rmse)\n",
    "print(D_rmse)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
